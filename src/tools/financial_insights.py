from pydantic import BaseModel, Field
from langchain_core.tools import tool
from langchain_core.messages import SystemMessage, HumanMessage
from psycopg.rows import dict_row
import json, textwrap, traceback, asyncio
from dependencies import get_llm, get_db_pool
from logger import log

MAX_RETRIES = 5
SCHEMA_HINT = textwrap.dedent("""\
    ### Tables
    transactions(id, statement_id, transaction_date, transaction_details, amount, category)
    
    statements(id, account_holder, account_name, start_date, end_date, opening_balance, closing_balance, credit_limit, interest_charged)
""")

class SQLSpec(BaseModel):
    """LLM must output *only* valid SQL in the `sql` field."""
    sql: str = Field(
        description="A single SELECT statement that answers the user question."
    )

def _get_sys_msg() -> SystemMessage:
    return SystemMessage(content=f"""
        Use the tables below to answer the user question **by emitting a single SQL SELECT statement** wrapped in JSON that matches the `SQLSpec` schema.

        ### Rules (follow strictly):
        1.  For comparing categories, use the following predefinied categories:
            - Groceries
            - Transport
            - Household Bills
            - Entertainment
            - Subscriptions
            - Healthcare
            - Dining
            - Vet & Pet Care
            - Shopping
            - Travel
            - Unknown
            
        2.  In this data set, expenses/outflows have POSITIVE amounts, income/inflows have NEGATIVE amounts.
        3.  When a month or year is mentioned, filter `DATE_TRUNC('month', transaction_date) = DATE '2025-04-01'` etc.
        4.  When asked for *largest/biggest transactions*, user is intersted in the largest outflows (expenses), which are positive amounts, ignore the negative amounts since they are inflows.
        5.  Transactions that says "ONLINE PAYMENT SYDNEY NS" are cerdit card payments made to the bank by the user, therefore they are not expenses.
        6.  Never modify the schema; only use listed tables/columns.

        {SCHEMA_HINT}
    """)

@tool
async def get_financial_insights(question: str) -> dict:
    """
    Provides financial insights by querying the database.

    Question examples:
      - "How much did I spend on groceries last month?"
      - "Show my total credit-card payments in April 2025."
      - "List the five biggest transactions this year."
    
    Args:
        question: User's question about their financial data.

    Returns:
        str: A narrative answer to the question, generated by the LLM.
        dict:
            {
                "response": A narrative answer to the question, generated by the LLM,
                "fatal_err": False
            }
            or
            {
                "fatal_err": True
            } on failure. 
    """


        
    error_feedback: str | None = None

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            pool = get_db_pool()
            plain_llm = get_llm()
            structured_llm = get_llm().with_structured_output(SQLSpec)

            # 1) Ask for SQL (include feedback from previous attempt if any)
            msgs = [_get_sys_msg(), HumanMessage(content=question)]
            
            if error_feedback:
                msgs.append(HumanMessage(content=f"""
                    Previous attempt failed:\n{error_feedback}\n
                    Please correct the SQL and try again.
                """))

            spec: SQLSpec = await structured_llm.ainvoke(msgs)
            
            log.info(f"[financial_insights] Attempt {attempt} SQL:\n{spec.sql}")
        
            # 2) Run the query
            async with pool.connection() as conn:
                async with conn.cursor(row_factory=dict_row) as cur:
                    await cur.execute(spec.sql)          # type: ignore[arg-type]
                    rows = await cur.fetchall()

            if not rows:
                raise ValueError("Query executed but returned zero rows.")

            # 3) Turn rows into narrative
            explain_msgs = [
                SystemMessage(content="Explain the query results clearly and concisely in plain English."),
                HumanMessage(content=f"""
                    Question: {question}\n
                    Result rows (JSON):\n
                    {json.dumps(rows, default=str)[:10_000]}
                """)]
            narrative = await plain_llm.ainvoke(explain_msgs)
            log.info("[financial_insights] LLM narrative: %s", narrative.content)

            return {
                "response": narrative.content,
                "fatal_err": False  
            }
    
        except Exception as e:
            tb = traceback.format_exception_only(type(e), e)[-1].strip()
            error_feedback = tb
            log.warning(f"[financial_insights] Attempt {attempt} failed: {tb}")

            if attempt == MAX_RETRIES:
                return {
                    "fatal_err": True,
                    "err_details": f"All {MAX_RETRIES} attempts failed: {tb}"
                }